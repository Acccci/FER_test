{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eTCVmhvCtHua"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61868, 1)   (61868,)\n",
      "(61868, 48, 48, 1)\n",
      "(61868, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 46, 46, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 46, 46, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 46, 46, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 46, 46, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 21, 21, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 21, 21, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 21, 21, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 21, 21, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               409800    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 688,849\n",
      "Trainable params: 688,017\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 20:37:18.888698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ywq/anaconda3/envs/FER/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-04-15 20:37:18.888750: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywq/anaconda3/envs/FER/lib/python3.8/site-packages/keras_metrics/metrics.py:26: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  return object.__getattribute__(self, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "1450/1451 [============================>.] - ETA: 0s - loss: 0.6405 - accuracy: 0.6345 - f1_score: 0.5946 - precision: 0.5978 - recall: 0.5917WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
      "1451/1451 [==============================] - 186s 126ms/step - loss: 0.6405 - accuracy: 0.6344 - f1_score: 0.5946 - precision: 0.5978 - recall: 0.5917 - val_loss: 0.5414 - val_accuracy: 0.7292 - val_f1_score: 0.6470 - val_precision: 0.6480 - val_recall: 0.6461\n",
      "Epoch 2/15\n",
      "1451/1451 [==============================] - 179s 123ms/step - loss: 0.5180 - accuracy: 0.7398 - f1_score: 0.6759 - precision: 0.6764 - recall: 0.6754 - val_loss: 0.4547 - val_accuracy: 0.7835 - val_f1_score: 0.6990 - val_precision: 0.6994 - val_recall: 0.6986\n",
      "Epoch 3/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.4182 - accuracy: 0.8058 - f1_score: 0.7182 - precision: 0.7182 - recall: 0.7181 - val_loss: 0.3693 - val_accuracy: 0.8384 - val_f1_score: 0.7373 - val_precision: 0.7354 - val_recall: 0.7391\n",
      "Epoch 4/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.3120 - accuracy: 0.8666 - f1_score: 0.7550 - precision: 0.7515 - recall: 0.7584 - val_loss: 0.2931 - val_accuracy: 0.8794 - val_f1_score: 0.7712 - val_precision: 0.7661 - val_recall: 0.7763\n",
      "Epoch 5/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.2155 - accuracy: 0.9162 - f1_score: 0.7864 - precision: 0.7801 - recall: 0.7928 - val_loss: 0.2242 - val_accuracy: 0.9103 - val_f1_score: 0.8006 - val_precision: 0.7932 - val_recall: 0.8082\n",
      "Epoch 6/15\n",
      "1451/1451 [==============================] - 178s 122ms/step - loss: 0.1452 - accuracy: 0.9456 - f1_score: 0.8133 - precision: 0.8050 - recall: 0.8217 - val_loss: 0.1840 - val_accuracy: 0.9287 - val_f1_score: 0.8244 - val_precision: 0.8157 - val_recall: 0.8333\n",
      "Epoch 7/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.0972 - accuracy: 0.9655 - f1_score: 0.8348 - precision: 0.8259 - recall: 0.8439 - val_loss: 0.1540 - val_accuracy: 0.9454 - val_f1_score: 0.8440 - val_precision: 0.8350 - val_recall: 0.8532\n",
      "Epoch 8/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.0730 - accuracy: 0.9746 - f1_score: 0.8523 - precision: 0.8433 - recall: 0.8614 - val_loss: 0.1393 - val_accuracy: 0.9482 - val_f1_score: 0.8596 - val_precision: 0.8512 - val_recall: 0.8683\n",
      "Epoch 9/15\n",
      "1451/1451 [==============================] - 177s 122ms/step - loss: 0.0584 - accuracy: 0.9802 - f1_score: 0.8663 - precision: 0.8583 - recall: 0.8744 - val_loss: 0.1785 - val_accuracy: 0.9383 - val_f1_score: 0.8721 - val_precision: 0.8645 - val_recall: 0.8799\n",
      "Epoch 10/15\n",
      "1451/1451 [==============================] - 178s 123ms/step - loss: 0.0478 - accuracy: 0.9843 - f1_score: 0.8774 - precision: 0.8701 - recall: 0.8847 - val_loss: 0.1197 - val_accuracy: 0.9645 - val_f1_score: 0.8826 - val_precision: 0.8753 - val_recall: 0.8899\n",
      "Epoch 11/15\n",
      "1451/1451 [==============================] - 178s 123ms/step - loss: 0.0442 - accuracy: 0.9852 - f1_score: 0.8872 - precision: 0.8800 - recall: 0.8946 - val_loss: 0.1513 - val_accuracy: 0.9536 - val_f1_score: 0.8914 - val_precision: 0.8842 - val_recall: 0.8988\n",
      "Epoch 12/15\n",
      "1451/1451 [==============================] - 179s 123ms/step - loss: 0.0407 - accuracy: 0.9867 - f1_score: 0.8953 - precision: 0.8879 - recall: 0.9027 - val_loss: 0.2139 - val_accuracy: 0.9379 - val_f1_score: 0.8986 - val_precision: 0.8910 - val_recall: 0.9063\n",
      "Epoch 13/15\n",
      "1451/1451 [==============================] - 180s 124ms/step - loss: 0.0394 - accuracy: 0.9867 - f1_score: 0.9017 - precision: 0.8938 - recall: 0.9096 - val_loss: 0.1415 - val_accuracy: 0.9592 - val_f1_score: 0.9048 - val_precision: 0.8969 - val_recall: 0.9127\n",
      "Epoch 14/15\n",
      "1451/1451 [==============================] - 179s 124ms/step - loss: 0.0346 - accuracy: 0.9882 - f1_score: 0.9076 - precision: 0.8998 - recall: 0.9156 - val_loss: 0.1299 - val_accuracy: 0.9619 - val_f1_score: 0.9103 - val_precision: 0.9024 - val_recall: 0.9182\n",
      "Epoch 15/15\n",
      "1451/1451 [==============================] - 178s 123ms/step - loss: 0.0300 - accuracy: 0.9907 - f1_score: 0.9128 - precision: 0.9050 - recall: 0.9208 - val_loss: 0.3582 - val_accuracy: 0.9081 - val_f1_score: 0.9148 - val_precision: 0.9065 - val_recall: 0.9232\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# for dirname,_,filenames in os.walk('kaggle/input'):\n",
    "#   for filename in filenames:\n",
    "#     print(os.path.join(diename, filename))\n",
    "from keras.layers.core.dropout import Dropout\n",
    "from keras.layers.core.dense import Dense\n",
    "from keras.layers.core.flatten import Flatten\n",
    "from keras.layers.core.activation import Activation\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Input,BatchNormalization, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras_preprocessing import image\n",
    "import scipy\n",
    "import os\n",
    "import cv2\n",
    "import keras_metrics as km\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./mylog/',\n",
    "        histogram_freq=1,\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "    \n",
    "data = pd.read_csv(\"./anger.csv\")\n",
    "\n",
    "#x数据集是图片的像素；y数据集是标签\n",
    "x_data = data[\"pixels\"]\n",
    "y_data = data[\"emotion\"]\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "oversampler = RandomOverSampler(sampling_strategy=\"auto\")\n",
    "\n",
    "#数据集预处理\n",
    "x_data, y_data = oversampler.fit_resample(x_data.values.reshape(-1,1),y_data)\n",
    "# x_data = x_data.values.reshape(-1, 1)\n",
    "# y_data = y_data.values.reshape(-1, 1)\n",
    "print(x_data.shape, \" \", y_data.shape)\n",
    "y_data.value_counts()\n",
    "y_data.shape\n",
    "x_data = pd.Series(x_data.flatten())\n",
    "x_data = np.array(list(map(str.split, x_data)), np.float32)\n",
    "x_data /= 255\n",
    "# x_data[:10]\n",
    "x_data = x_data.reshape(-1, 48, 48, 1)\n",
    "print(x_data.shape)\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(y_data.shape[0], 1)\n",
    "print(y_data.shape)\n",
    "x_train,x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=45)\n",
    "\n",
    "model = Sequential([ \n",
    "  Input((48, 48, 1)),\n",
    "  Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid'),\n",
    "  BatchNormalization(axis=3),\n",
    "  Activation('relu'),\n",
    "  Conv2D(64, (3,3), strides=(1,1), padding='same'),\n",
    "  BatchNormalization(axis=3),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D((2,2)),\n",
    "  Conv2D(64, (3, 3), strides=(1,1), padding='valid'),\n",
    "  BatchNormalization(axis=3),\n",
    "  Activation('relu'),\n",
    "  Conv2D(128,(3, 3), strides=(1, 1), padding='same'),\n",
    "  BatchNormalization(axis=3),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Conv2D(128, (3, 3), strides=(1, 1), padding='valid'),\n",
    "  BatchNormalization(axis=3),\n",
    "  Activation('relu'),\n",
    "  MaxPooling2D((2,2)),\n",
    "  Flatten(),\n",
    "  Dense(200, activation='relu'),\n",
    "  Dropout(0.6),\n",
    "  Dense(1,activation='sigmoid')  # 如果是一分类表情识别， 此处为1；\n",
    "  ])\n",
    "model.summary()\n",
    "adam = keras.optimizers.adam_v2.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy',km.f1_score(),km.binary_precision(),km.binary_recall()])\n",
    "# y_train = np_utils.to_categorical(y_train, 2)\n",
    "# y_train.shape\n",
    "# y_test = np_utils.to_categorical(y_test, 2)\n",
    "# y_test.shape\n",
    "#模型训练\n",
    "history = model.fit(x_train,y_train,epochs=15,validation_data=(x_test, y_test),callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oxvXCbGerNTx",
    "outputId": "01c19d0a-c18e-4b51-8361-8981be247058"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1475640501.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [28]\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.title('f1_score')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_metrics as km\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()\n",
    "#summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()\n",
    "#summarize history for f1\n",
    "plt.plot(history.history['km.f1_score']\n",
    "plt.title('f1_score')\n",
    "plt.ylabel('f1_score')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()\n",
    "# y_pred=model.predict(x_test)\n",
    "# y_result=[]\n",
    "# for pred in y_pred:\n",
    "#   y_result.append(np.argmax(pred))\n",
    "# print(y_result[:])\n",
    "# y_actual=[]\n",
    "# for pred in y_test:\n",
    "#   y_actual.append(np.argmax(pred))\n",
    "# print(y_actual[:])\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# print(classification_report(y_actual,y_result))\n",
    "\n",
    "# import seaborn as sn\n",
    "# cm = tf.math.confusion_matrix(labels=y_actual,predictions=y_result)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,7))\n",
    "# sn.heatmap(cm,annot=True,fmt='d')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Truth')\n",
    "# fer_json=model.to_json()\n",
    "# with open(\"fer_json\", \"w\") as json_file:\n",
    "#   json_file.write(fer_json)\n",
    "\n",
    "# #保存模型\n",
    "# model.save_weights(\"./anger_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwrFc7J9LaLN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_a0aKNzLRgc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "表情识别.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
